{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8486704-de48-40e5-a432-c30224b30b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (6497, 11) [[ 0.23   0.25  17.3   ...  0.42   9.2    6.   ]\n",
      " [ 0.43   0.37  10.    ...  0.64   9.5    5.   ]\n",
      " [ 0.25   0.49   2.7   ...  0.9   10.     6.   ]\n",
      " ...\n",
      " [ 0.5    0.35   2.9   ...  0.62   9.4    5.   ]\n",
      " [ 0.305  0.39   1.2   ...  0.52  11.5    6.   ]\n",
      " [ 0.41   0.39   2.2   ...  0.65  10.2    5.   ]]\n",
      "Shape of Y: (6497, 1)\n"
     ]
    }
   ],
   "source": [
    "# import packages \n",
    "import numpy as np\n",
    "import math, random \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "# open the csv files with pandas \n",
    "df_red = pd.read_csv('winequality-red.csv',delimiter=\";\")\n",
    "df_white = pd.read_csv('winequality-white.csv',delimiter=\";\")\n",
    "\n",
    "# asign label 1 for red wine and label 0 for white wine\n",
    "df_red[\"color\"] = 1\n",
    "df_white[\"color\"] = 0 \n",
    "\n",
    "\n",
    "# combine the 2 data frames and then shufle them \n",
    "df = pd.concat([df_red, df_white])\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# select the atributes used to perform the prediction\n",
    "\n",
    "# all the atributes exept the color where asigned to the variable X \n",
    "X = df.iloc[:,1:-1].to_numpy()\n",
    "\n",
    "# asign the color atribute to the variable Y\n",
    "\n",
    "Y = df[['color']].to_numpy()\n",
    "\n",
    "print(\"Shape of X:\", X.shape , X)\n",
    "print(\"Shape of Y:\", Y.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfd0cef0-09aa-4982-9304-50d2b55fc0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single neuron model clasification class \n",
    "\n",
    "class single_neuron_classification_model():\n",
    "    \n",
    "    # init method\n",
    "    \n",
    "    def __init__(self, input_data ,output_data ):\n",
    "        self.input_data = input_data  \n",
    "        self.output_data = output_data \n",
    "        \n",
    "        # initialize randomized weigths \n",
    "        self.w = 0.01 * np.random.randn(self.input_data.shape[1])\n",
    "        self.w_0 = 0.01 * np.random.randn()\n",
    "     \n",
    "    \n",
    "    # sigmoid activation \n",
    "    def sigmoid(self,z): \n",
    "        non_zero_tolerance = 1e-8\n",
    "        return 1 / (1 + math.exp(-z) + non_zero_tolerance)      \n",
    "\n",
    "    # function to compute the output of the model\n",
    "    def forward (self , x ):\n",
    "        \n",
    "        # Calculate pre-activation z\n",
    "        z = x @ self.w.T + self.w_0\n",
    "    \n",
    "        # activation funcion\n",
    "        a = self.sigmoid(z)\n",
    "        return a\n",
    "\n",
    "\n",
    "    # training function \n",
    "\n",
    "    def train_model_NLL_loss(self , learning_rate , num_epochs):\n",
    "        \n",
    "        # ensure avoiding log of 0 \n",
    "        non_zero_tolerance = 1e-8 \n",
    "    \n",
    "         \n",
    "    \n",
    "        for epoch in range(num_epochs):\n",
    "            # keep track of total loss\n",
    "            total_loss = 0 \n",
    "        \n",
    "            for x , y in zip( self.input_data , self.output_data):\n",
    "                \n",
    "                y_predicted = self.forward(x) \n",
    "                nll_loss = -(y * math.log(y_predicted + non_zero_tolerance) + (1-y) * math.log(1-y_predicted + non_zero_tolerance))\n",
    "            \n",
    "                total_loss += nll_loss\n",
    "            \n",
    "                \n",
    "                # update bias coeficient using the gradients \n",
    "            \n",
    "                self.w_0 -= learning_rate * (y_predicted - y)\n",
    "            \n",
    "                # update model coeficients using the gradients  \n",
    "            \n",
    "                for j, x_j in enumerate(x):\n",
    "                    self.w[j] -= learning_rate * (y_predicted - y) * x_j\n",
    "            \n",
    "                \n",
    "            # print loss at some epochs \n",
    "            report_every = max(1, num_epochs // 10)\n",
    "            if epoch % report_every == 0: #every few epochs, report on progress\n",
    "                print(\"epoch\", epoch, \"has total loss\", total_loss)\n",
    "           \n",
    "        return self.w, self.w_0\n",
    "\n",
    "# evaluation function\n",
    "\n",
    "def evaluate_classification_accuracy(model, input_data, labels):\n",
    "    # Count the number of correctly classified samples given a set of weights\n",
    "    correct = 0\n",
    "    num_samples = len(input_data)\n",
    "    for i in range(num_samples):\n",
    "        x = input_data[i,:]\n",
    "        y = labels[i]\n",
    "        y_predicted = model.forward(x)\n",
    "        label_predicted = 1 if y_predicted > 0.5 else 0\n",
    "        if label_predicted == y:\n",
    "            correct += 1\n",
    "    accuracy = correct / num_samples\n",
    "    print(\"Our model predicted\", correct, \"out of\", num_samples,\n",
    "          \"correctly for\", accuracy*100, \"% accuracy\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2d81e10-66fa-4093-b6fa-97ba51446117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 has total loss [4137.21477836]\n",
      "epoch 20 has total loss [2851.34379812]\n",
      "epoch 40 has total loss [2421.24623923]\n",
      "epoch 60 has total loss [2153.06271791]\n",
      "epoch 80 has total loss [2019.12311044]\n",
      "epoch 100 has total loss [1895.78829091]\n",
      "epoch 120 has total loss [1806.93686478]\n",
      "epoch 140 has total loss [1746.44930913]\n",
      "epoch 160 has total loss [1693.96063553]\n",
      "epoch 180 has total loss [1641.92773399]\n",
      "Our model predicted 3727 out of 6497 correctly for 57.36493766353702 % accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5736493766353702"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set parameters for training \n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 200\n",
    "\n",
    "# set the model \n",
    "model = single_neuron_classification_model(input_data = X , \n",
    "                                           output_data = Y )\n",
    "\n",
    "# train the model\n",
    "model.train_model_NLL_loss( learning_rate = learning_rate ,\n",
    "                           num_epochs = num_epochs)\n",
    "# evaluate the model\n",
    "evaluate_classification_accuracy(model,X,Y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42620658-7c52-46a3-9e7f-9e0adc97bc28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f148cad-40d1-4eb9-8ee5-54837c9c3e28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
